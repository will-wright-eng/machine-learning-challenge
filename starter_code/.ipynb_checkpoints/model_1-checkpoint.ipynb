{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update sklearn to prevent version mismatches\n",
    "!pip install sklearn --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install joblib. This will be used to save your model. \n",
    "# Restart your kernel after installing \n",
    "!pip install joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the CSV and Perform Basic Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"exoplanet_data.csv\")\n",
    "# # Drop the null columns where all values are null\n",
    "# df = df.dropna(axis='columns', how='all')\n",
    "# # Drop the null rows\n",
    "# df = df.dropna()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('cumulative.csv')\n",
    "\n",
    "# print(len(df))\n",
    "\n",
    "# # Drop the null columns where all values are null\n",
    "# df = df.dropna(axis='columns', how='all')\n",
    "# print(len(df))\n",
    "# # Drop the null rows\n",
    "# df = df.dropna()\n",
    "\n",
    "# print(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select your features (columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "koi_steff          9201\n",
       "koi_slogg          9201\n",
       "koi_srad           9201\n",
       "koi_disposition    9564\n",
       "kepid              9564\n",
       "koi_period         9564\n",
       "koi_prad           9201\n",
       "koi_teq            9201\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "koi_steff          float64\n",
       "koi_slogg          float64\n",
       "koi_srad           float64\n",
       "koi_disposition     object\n",
       "kepid                int64\n",
       "koi_period         float64\n",
       "koi_prad           float64\n",
       "koi_teq            float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_mapping = {\n",
    "    # stellar parameters\n",
    "    'koi_steff' : 'stellar effective temperature (Kelvin)'\n",
    "    , 'koi_slogg' : 'stellar surface gravity (base-10 logarithm)'\n",
    "    , 'koi_srad' : 'stellar radius (solar radii)'\n",
    "    # exoplanet archive information\n",
    "    , 'koi_disposition' : 'exoplanet archive disposition'\n",
    "#     , 'kepoi_name' : 'kepler object of interest -- name'\n",
    "    # identification columns\n",
    "    , 'kepid' : 'target identification number'\n",
    "    # transit properties\n",
    "    , 'koi_period' : 'orbital period (days)'\n",
    "    , 'koi_prad' : 'planetary radius (earth radii)'\n",
    "    , 'koi_teq' : 'equilibrium temperature (kelvin)'\n",
    "\n",
    "}\n",
    "\n",
    "df = df[list(col_mapping)]\n",
    "df.head()\n",
    "\n",
    "display(df.count())\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Train Test Split\n",
    "\n",
    "Use `koi_disposition` for the y values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9564, 7) (9564,)\n"
     ]
    }
   ],
   "source": [
    "# Assign X (data) and y (target)\n",
    "label = 'koi_disposition'\n",
    "X = df.drop(label, axis=1)\n",
    "y = df[label]\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>koi_steff</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>kepid</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_prad</th>\n",
       "      <th>koi_teq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7255</th>\n",
       "      <td>5693.0</td>\n",
       "      <td>4.551</td>\n",
       "      <td>0.856</td>\n",
       "      <td>10793172</td>\n",
       "      <td>18.081143</td>\n",
       "      <td>0.75</td>\n",
       "      <td>638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4932</th>\n",
       "      <td>7564.0</td>\n",
       "      <td>4.093</td>\n",
       "      <td>1.893</td>\n",
       "      <td>8177798</td>\n",
       "      <td>1.450206</td>\n",
       "      <td>92.78</td>\n",
       "      <td>2675.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1398</th>\n",
       "      <td>4650.0</td>\n",
       "      <td>4.589</td>\n",
       "      <td>0.706</td>\n",
       "      <td>6026438</td>\n",
       "      <td>5.476658</td>\n",
       "      <td>2.01</td>\n",
       "      <td>741.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7750</th>\n",
       "      <td>6387.0</td>\n",
       "      <td>4.398</td>\n",
       "      <td>1.076</td>\n",
       "      <td>7970760</td>\n",
       "      <td>7.649413</td>\n",
       "      <td>53.40</td>\n",
       "      <td>1050.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>5566.0</td>\n",
       "      <td>4.532</td>\n",
       "      <td>0.886</td>\n",
       "      <td>7770450</td>\n",
       "      <td>1.157808</td>\n",
       "      <td>22.90</td>\n",
       "      <td>1579.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      koi_steff  koi_slogg  koi_srad     kepid  koi_period  koi_prad  koi_teq\n",
       "7255     5693.0      4.551     0.856  10793172   18.081143      0.75    638.0\n",
       "4932     7564.0      4.093     1.893   8177798    1.450206     92.78   2675.0\n",
       "1398     4650.0      4.589     0.706   6026438    5.476658      2.01    741.0\n",
       "7750     6387.0      4.398     1.076   7970760    7.649413     53.40   1050.0\n",
       "1214     5566.0      4.532     0.886   7770450    1.157808     22.90   1579.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "X_train.head()\n",
    "# X_train.reshape(-1, 1)\n",
    "# np.array(X_train).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "\n",
    "Scale the data using the MinMaxScaler and perform some feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Scale your data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create a StandardScater model and fit it to the training data\n",
    "\n",
    "# np.array(X_train).reshape(-1, 1)\n",
    "# X_scaler = StandardScaler().fit(X_train.reshape(-1, 1))\n",
    "X_scaler = StandardScaler().fit(np.array(X_train).reshape(-1, 1))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-4b90a93bf6fa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Training Data Score: {model2.score(X_train_scaled, y_train)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model2' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {model2.score(X_train_scaled, y_train)}\")\n",
    "print(f\"Testing Data Score: {model2.score(X_test_scaled, y_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning\n",
    "\n",
    "Use `GridSearchCV` to tune the model's parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the GridSearchCV model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model with GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(grid2.best_params_)\n",
    "print(grid2.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save your model by updating \"your_name\" with your name\n",
    "# and \"your_model\" with your model variable\n",
    "# be sure to turn this in to BCS\n",
    "# if joblib fails to import, try running the command to install in terminal/git-bash\n",
    "import joblib\n",
    "filename = 'your_name.sav'\n",
    "joblib.dump(your_model, filename)"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "dev"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
